# Fine-tune-and-quantize-LLM-using-Q-LoRA
This repository contains a complete pipeline for fine-tuning Large Language Models (LLMs) using Hugging Face Transformers, PEFT (Parameter-Efficient Fine-Tuning), and TRL (Transformers Reinforcement Learning). The project leverages LoRA (Low-Rank Adaptation) to efficiently fine-tune models while optimizing memory usage.
